{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Args\n",
    "Setup args used by program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read args\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# db = sys.argv[1]\n",
    "db = \"../scrape/seriouseats/seriouseats.db\"\n",
    "\n",
    "limit = 500\n",
    "\n",
    "# num_clusters = int(sys.argv[2])\n",
    "num_clusters = 12\n",
    "\n",
    "# 0 means keep all edges\n",
    "min_edge_weight = 0\n",
    "\n",
    "# progress bars\n",
    "def progress(count, total, status=''):\n",
    "    width = 60\n",
    "    percents = round(100.0 * (count + 1) / float(total), 1)\n",
    "    progress = (count + 1) / total\n",
    "    progress = min(1, max(0, progress))\n",
    "    whole_width = math.floor(progress * width)\n",
    "    remainder_width = (progress * width) % 1\n",
    "    part_width = math.floor(remainder_width * 8)\n",
    "    part_char = [\" \", \"▏\", \"▎\", \"▍\", \"▌\", \"▋\", \"▊\", \"▉\"][part_width]\n",
    "    if (width - whole_width - 1) < 0:\n",
    "        part_char = \"\"\n",
    "    bar = \"[\" + \"█\" * whole_width + part_char + \" \" * (width - whole_width - 1) + \"]\"\n",
    "\n",
    "    sys.stdout.write('%s %s%s %s\\r' % (bar, percents, '%', status))\n",
    "    if (width - whole_width - 1) < 0:\n",
    "        sys.stdout.write(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# filename with timestamp\n",
    "def get_filename(filename, ext):\n",
    "    date = datetime.now().strftime(\"%Y_%m_%d-%I-%M-%S_%p\")\n",
    "    return f\"{filename}_{date}.{ext}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "Read in data from sqlite3 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read Data\n",
    "%time\n",
    "import sqlite3\n",
    "\n",
    "# open db\n",
    "con = sqlite3.connect(db)\n",
    "cur = con.cursor()\n",
    "\n",
    "# read recipes\n",
    "cur.execute(\n",
    "    \"\"\"\n",
    "    select r.id, r.title, t.tag, i.ingredient\n",
    "    from (\n",
    "        select *\n",
    "        from recipes\n",
    "        limit ?\n",
    "    ) r\n",
    "    inner join ingredients i on r.id = i.recipeid\n",
    "    left join tags t on r.id = t.recipeid\n",
    "    \"\"\",\n",
    "    [limit],\n",
    ")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "cur.close()\n",
    "print(\"Loaded {:d} rows\".format(len(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup Data\n",
    "Current process removes nltk stopwords, custom stopwords, and uses nltk to strip non-nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Cleanup\n",
    "import re\n",
    "import os\n",
    "\n",
    "%time\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "\n",
    "# helpers for removing things\n",
    "only_alpha = re.compile(\"[^a-zA-Z\\\\s]\")\n",
    "\n",
    "# pluralize\n",
    "def pluralize(words):\n",
    "    return [w + \"s\" for w in words] + [w + \"es\" for w in words]\n",
    "\n",
    "custom_stopwords_filepath = os.path.join(\n",
    "    Path().resolve(), \"custom_stopwords.txt\"\n",
    ")\n",
    "\n",
    "custom_stopwords = set(\n",
    "    [\n",
    "        w\n",
    "        for w in open(custom_stopwords_filepath).read().split(\"\\n\")\n",
    "        if not w.startswith(\"#\") and not w.isspace() and not w == \"\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# expand stop words here (e.g. measurments and common ingredients (minced, etc))\n",
    "# look into collecting existing lists\n",
    "stop_words = (\n",
    "    set(stopwords.words(\"english\"))\n",
    "    | set(custom_stopwords)\n",
    "    | set(pluralize(custom_stopwords))\n",
    ")\n",
    "\n",
    "# create results to work with\n",
    "results = {}\n",
    "for i, [id, title, tag, ingredient] in enumerate(rows):\n",
    "    progress(i, len(rows), \"Cleaning\")\n",
    "    results[id] = {\n",
    "        \"title\": title,\n",
    "        \"values\":\n",
    "            # existing results\n",
    "            (results[id].get(\"values\") if id in results else set())\n",
    "            # tags\n",
    "            # | set([tag.lower()])\n",
    "            # ingredients\n",
    "            | set(\n",
    "                [\n",
    "                    w\n",
    "                    for w, pos in pos_tag(\n",
    "                        word_tokenize(only_alpha.sub(\" \", ingredient).lower())\n",
    "                    )\n",
    "                    if not w in stop_words\n",
    "                    and len(w) > 2\n",
    "                    and (pos == \"NN\" or pos == \"NNP\" or pos == \"NNS\" or pos == \"NNPS\")\n",
    "                ]\n",
    "            ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Perform clustering via [kmeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clustering\n",
    "%time\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "# encode data\n",
    "words = sorted(\n",
    "    set([value for result in results.values() for value in result[\"values\"]])\n",
    ")\n",
    "\n",
    "words_to_index = {key: i for i, key in enumerate(words)}\n",
    "encoded = np.zeros((len(results), len(words)))\n",
    "for i, (_, result) in enumerate(results.items()):\n",
    "    progress(i, len(results), \"Encoding\")\n",
    "    for word in result[\"values\"]:\n",
    "        if word in words_to_index:\n",
    "            encoded[i][words_to_index[word]] = 1\n",
    "\n",
    "# cluster\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(encoded)\n",
    "clusters = [\n",
    "    (pair[0], pair[1][0], pair[1][1][\"title\"], pair[1][1][\"values\"])\n",
    "    for pair in zip(kmeans.labels_, results.items())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Generation\n",
    "Generate graph using [networkx](https://networkx.org/documentation/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph Generation\n",
    "%time\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "\n",
    "g = nx.Graph()\n",
    "edges = {}\n",
    "node_labels = []\n",
    "for i, (cluster, id, title, values) in enumerate(clusters):\n",
    "    progress(i, len(results), \"Generating Nodes and Edges\")\n",
    "    label = (title[:20] + \"..\") if len(title) > 20 else title\n",
    "    g.add_node(\n",
    "        i,\n",
    "        Title=title,\n",
    "        Label=label,\n",
    "        ID=id,\n",
    "        Cluster=cluster,\n",
    "        KeyWords=\", \".join(values),\n",
    "        NumKeyWords=len(values),\n",
    "    )\n",
    "\n",
    "    node_labels.append(label)\n",
    "\n",
    "    for word in values:\n",
    "        for j, row in enumerate(encoded):\n",
    "            if i != j and row[words_to_index[word]] == 1:\n",
    "                if (j, i) in edges:\n",
    "                    edges[(j, i)] += 1\n",
    "                elif (i, j) in edges:\n",
    "                    edges[(i, j)] += 1\n",
    "                else:\n",
    "                    edges[(i, j)] = 1\n",
    "\n",
    "# weight by matches\n",
    "# max_weight = max(edges.items(), key=operator.itemgetter(1))[1]\n",
    "# edges = {(i, j): w / max_weight for (i, j), w in edges.items()}\n",
    "\n",
    "# weight by cluster\n",
    "#edges = {\n",
    "#    (i, j): int(clusters[i][0] == clusters[j][0])\n",
    "#    for (i, j), _ in edges.items()\n",
    "#}\n",
    "\n",
    "# weight by mixture\n",
    "max_weight = max(edges.items(), key=operator.itemgetter(1))[1]\n",
    "edges = {\n",
    "    (i, j): w / max_weight * (int(clusters[i][0] == clusters[j][0]) + 1)\n",
    "    for (i, j), w in edges.items()\n",
    "}\n",
    "\n",
    "for k, ((i, j), w) in enumerate(edges.items()):\n",
    "    progress(k, len(edges), \"Attaching Edges\")\n",
    "    if w >= min_edge_weight:\n",
    "        g.add_edge(i, j, weight=w)\n",
    "\n",
    "# calc communities\n",
    "communities = community.greedy_modularity_communities(g)\n",
    "print(\"{:d} nodes and {:d} edges\".format(len(g.nodes()), len(g.edges())))\n",
    "print(\"Retained {:d} of {:d} possible edges\".format(len(g.edges()), len(edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bokeh Render\n",
    "Render using [bokeh](https://bokeh.org).\n",
    "\n",
    "Learned from this nice site https://melaniewalsh.github.io/Intro-Cultural-Analytics/06-Network-Analysis/00-Network-Analysis.html.\n",
    "\n",
    "Works okay for low number of nodes/edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bokeh Visualization\n",
    "%%script false --no-raise-error\n",
    "%time\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.io import output_notebook, output_file, save, show, curdoc\n",
    "from bokeh.themes import built_in_themes\n",
    "from bokeh.models import (\n",
    "    Range1d,\n",
    "    Circle,\n",
    "    HoverTool,\n",
    "    MultiLine,\n",
    "    LabelSet,\n",
    "    ColumnDataSource,\n",
    "    NodesAndLinkedEdges,\n",
    ")\n",
    "from bokeh.plotting import figure, column\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import Viridis8\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# title\n",
    "curdoc().theme = \"dark_minimal\"\n",
    "title = \"Recipes Visualization\"\n",
    "\n",
    "# Create a plot — set dimensions, toolbar, and title\n",
    "plot = figure(\n",
    "    tools=\"pan,wheel_zoom,save,reset,hover\",\n",
    "    active_scroll=\"wheel_zoom\",\n",
    "    x_range=Range1d(-10.1, 10.1),\n",
    "    y_range=Range1d(-10.1, 10.1),\n",
    "    title=title,\n",
    ")\n",
    "\n",
    "# Create a network graph object with spring layout\n",
    "# https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.drawing.layout.spring_layout.html\n",
    "network_graph = from_networkx(\n",
    "    g,\n",
    "    nx.spring_layout,\n",
    "    scale=10,\n",
    "    center=(0, 0),\n",
    ")\n",
    "\n",
    "# settings\n",
    "size_by = \"NumKeyWords\"\n",
    "\n",
    "color_by = \"modularity_color\"\n",
    "node_color_by = linear_cmap(\"Cluster\", Viridis8, 0, num_clusters)\n",
    "\n",
    "edge_color_by = \"black\"\n",
    "edge_opacity_by = \"weight\"\n",
    "\n",
    "node_highlight_color = \"white\"\n",
    "edge_highlight_color = \"black\"\n",
    "\n",
    "# Set node size and color\n",
    "network_graph.node_renderer.glyph = Circle(\n",
    "    size=size_by,\n",
    "    fill_color=node_color_by,\n",
    ")\n",
    "\n",
    "# Set node highlight colors\n",
    "network_graph.node_renderer.hover_glyph = Circle(\n",
    "    size=size_by, fill_color=node_highlight_color, line_width=2\n",
    ")\n",
    "network_graph.node_renderer.selection_glyph = Circle(\n",
    "    size=size_by, fill_color=node_highlight_color, line_width=2\n",
    ")\n",
    "\n",
    "# Set edge opacity and width\n",
    "network_graph.edge_renderer.glyph = MultiLine(\n",
    "    line_alpha=0.1, line_color=edge_color_by, line_width=1\n",
    ")\n",
    "\n",
    "# Set edge highlight colors\n",
    "network_graph.edge_renderer.selection_glyph = MultiLine(\n",
    "    line_color=edge_highlight_color, line_width=2\n",
    ")\n",
    "network_graph.edge_renderer.hover_glyph = MultiLine(\n",
    "    line_color=edge_highlight_color, line_width=2\n",
    ")\n",
    "\n",
    "# Highlight nodes and edges\n",
    "network_graph.selection_policy = NodesAndLinkedEdges()\n",
    "network_graph.inspection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "# Add network graph to the plot\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "x, y = zip(*network_graph.layout_provider.graph_layout.values())\n",
    "source = ColumnDataSource(\n",
    "    {\"x\": x, \"y\": y, \"name\": [node_labels[i] for i in range(len(x))]}\n",
    ")\n",
    "\n",
    "labels = LabelSet(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    text=\"name\",\n",
    "    source=source,\n",
    "    background_fill_color=\"white\",\n",
    "    text_font_size=\"10px\",\n",
    "    background_fill_alpha=0.7,\n",
    "    text_align=\"center\",\n",
    ")\n",
    "plot.renderers.append(labels)\n",
    "\n",
    "# setup tooltip\n",
    "tooltips = \"\"\"\n",
    "    <div style=\"font-family: Helvetica;\n",
    "                border: 1px solid black;\n",
    "                background-color: white;\n",
    "                width : 200px;\n",
    "                position: fixed;\n",
    "                left: 65px;\n",
    "                top: 45px;\n",
    "                padding: 10px\">\n",
    "\n",
    "    <span style=\"font-size: 16px;\"><b>Title:</b> @Title</span><br>\n",
    "    <span style=\"font-size: 16px;\"><b>Cluster:</b> @Cluster</span><br>\n",
    "    <span style=\"font-size: 16px;\"><b>Keywords:</b> @KeyWords</span><br>\n",
    "    <img src=\"http://localhost/images/recipe/@ID\" />\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "hover = plot.select_one(HoverTool)\n",
    "hover.show_arrow = False\n",
    "hover.tooltips = tooltips\n",
    "\n",
    "# layout\n",
    "column(plot)\n",
    "\n",
    "# display\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datashader Rendering\n",
    "Render using [datashader](https://datashader.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Datashader Render\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.layout import random_layout, circular_layout, forceatlas2_layout\n",
    "from datashader.bundling import connect_edges, hammer_bundle\n",
    "import pandas as pd\n",
    "from holoviews.plotting.util import process_cmap\n",
    "\n",
    "cvsopts = dict(plot_height=800, plot_width=800)\n",
    "\n",
    "\n",
    "def nodesplot(nodes, name=None, canvas=None, cat=None):\n",
    "    canvas = ds.Canvas(**cvsopts) if canvas is None else canvas\n",
    "    aggregator = None if cat is None else ds.count_cat(cat)\n",
    "    agg = canvas.points(nodes, \"x\", \"y\", aggregator)\n",
    "\n",
    "    color_key = [\"#00FF00\"]\n",
    "\n",
    "    if cat is not None:\n",
    "        cats = set([c for c in nodes[cat]])\n",
    "        color_key = process_cmap(\"Viridis\", provider=\"bokeh\", ncolors=len(cats))\n",
    "\n",
    "    return tf.spread(\n",
    "        tf.shade(agg, color_key=color_key),\n",
    "        px=3, name=name,\n",
    "    )\n",
    "\n",
    "\n",
    "def edgesplot(edges, name=None, canvas=None):\n",
    "    canvas = ds.Canvas(**cvsopts) if canvas is None else canvas\n",
    "    return tf.shade(\n",
    "        canvas.line(edges, \"x\", \"y\", agg=ds.count()),\n",
    "        name=name,\n",
    "        cmap=process_cmap(\"Viridis\", provider=\"bokeh\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def graphplot(nodes, edges, name=\"\", canvas=None, cat=None):\n",
    "    if canvas is None:\n",
    "        xr = nodes.x.min(), nodes.x.max()\n",
    "        yr = nodes.y.min(), nodes.y.max()\n",
    "        canvas = ds.Canvas(x_range=xr, y_range=yr, **cvsopts)\n",
    "\n",
    "    np = nodesplot(nodes, name + \" nodes\", canvas, cat)\n",
    "    ep = edgesplot(edges, name + \" edges\", canvas)\n",
    "    return tf.stack(ep, np, how=\"over\", name=name)\n",
    "\n",
    "\n",
    "def nx_layout(graph, cat=None):\n",
    "    layout = nx.spring_layout(graph, iterations=100)\n",
    "    data = [\n",
    "        [node[0]]  # index\n",
    "        + layout[node[0]].tolist()  # x,y\n",
    "        + ([] if cat is None else [node[1][cat]])\n",
    "        for node in graph.nodes(data=True)\n",
    "    ]\n",
    "\n",
    "    columns = [\"id\", \"x\", \"y\"] + ([] if cat is None else [cat])\n",
    "    nodes = pd.DataFrame(data, columns=columns)\n",
    "    nodes.set_index(\"id\", inplace=True)\n",
    "\n",
    "    if cat is not None:\n",
    "        nodes[cat] = nodes[cat].astype(\"category\")\n",
    " \n",
    "    edges = pd.DataFrame(list(graph.edges), columns=[\"source\", \"target\"])\n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "def nx_plot(graph, name=\"\", cat=None):\n",
    "    nodes, edges = nx_layout(graph, cat)\n",
    "\n",
    "    # direct = connect_edges(nodes, edges)\n",
    "    # bundled_bw005 = hammer_bundle(nodes, edges)\n",
    "    bundled_bw030 = hammer_bundle(nodes, edges, initial_bandwidth=0.30)\n",
    "\n",
    "    return (graphplot(nodes, bundled_bw030, name, cat=cat), nodes, edges)\n",
    "\n",
    "\n",
    "(plot, nodes, edges) = nx_plot(g, \"Recipes\", cat=\"Cluster\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datashader Image Output\n",
    "Output datashader results to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Datashader Visualization\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "\n",
    "def draw_text(img, text, x, y, size=30, face=\"Regular\", color=(230, 230, 230)):\n",
    "    \"\"\"Helper to draw text labels using PIL.\"\"\"\n",
    "    # This font path assumes you're using a Mac with Open Sans installed.\n",
    "    fnt = ImageFont.load_default()\n",
    "    try:\n",
    "        fnt = ImageFont.truetype(f\"~/Library/Fonts/OpenSans-{face}.ttf\", size)\n",
    "    except:\n",
    "        pass\n",
    "    d = ImageDraw.Draw(img)\n",
    "    bbox = d.textbbox((x, y), text, fnt)\n",
    "    d.text((bbox[0], bbox[1]), text, font=fnt, fill=color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def tile_images(images):\n",
    "    # Tile the three images side by side\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    width = sum(widths)\n",
    "    height = max(heights)\n",
    "    output = Image.new(\"RGB\", (width, height), (26, 24, 38))\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "        output.paste(im, (x_offset, 0))\n",
    "        x_offset += im.size[0]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "imgs = [draw_text(tf.set_background(plot, (26, 24, 38)).to_pil(), plot.name, 15, 0)]\n",
    "output = tile_images(imgs)\n",
    "output.save(get_filename(\"output/cluster\", \"png\"))\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datashader Interactive Output\n",
    "Make datashader plots interactive with bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from holoviews.plotting.util import process_cmap\n",
    "from holoviews.operation.datashader import datashade, bundle_graph\n",
    "from bokeh.models import HoverTool\n",
    "hv.extension(\"bokeh\")\n",
    "hv.renderer('bokeh').theme = 'dark_minimal'\n",
    "\n",
    "tooltips = \"\"\"\n",
    "    <div style=\"font-family: Helvetica;\n",
    "                border: 1px solid black;\n",
    "                background-color: white;\n",
    "                width : 200px;\n",
    "                position: fixed;\n",
    "                left: 65px;\n",
    "                top: 45px;\n",
    "                padding: 10px\">\n",
    "\n",
    "    <span style=\"font-size: 16px;\"><b>Title:</b> @Title</span><br>\n",
    "    <span style=\"font-size: 16px;\"><b>Cluster:</b> @Cluster</span><br>\n",
    "    <span style=\"font-size: 16px;\"><b>Keywords:</b> @KeyWords</span><br>\n",
    "    <img  style=\"max-width: 200px;\" src=\"http://localhost/images/recipe/@ID\" />\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "hover = HoverTool(tooltips=tooltips)\n",
    "\n",
    "# defaults\n",
    "kwargs = dict(width=800,height=800, xaxis=None, yaxis=None)\n",
    "nodes_kwargs = {**kwargs, **dict(size = 15)}\n",
    "opts.defaults(\n",
    "    opts.Nodes(**nodes_kwargs), opts.Graph(**kwargs)\n",
    ")\n",
    "\n",
    "# settings\n",
    "node_cmap=process_cmap(\"Viridis\", provider=\"bokeh\")\n",
    "\n",
    "# create graph\n",
    "graph = hv.Graph.from_networkx(g, nx.layout.fruchterman_reingold_layout)\n",
    "graph.opts(\n",
    "    width=800,height=800,\n",
    "    cmap=node_cmap,\n",
    "    edge_line_width=1, \n",
    "    node_color='Cluster',\n",
    "    tools=[hover],\n",
    "    active_tools=[\"wheel_zoom\"],\n",
    "    bgcolor=(26, 24, 38)\n",
    ")\n",
    "\n",
    "\n",
    "graph = bundle_graph(graph)\n",
    "labels = hv.Labels(graph.nodes, ['x', 'y'], 'Label')\n",
    "\n",
    "# combine graphs\n",
    "graph = (\n",
    "    (datashade(graph, normalization='linear', cmap=node_cmap, width=800, height=800) * graph.nodes).opts(\n",
    "        opts.Nodes(color='Cluster', size='NumKeyWords', cmap=node_cmap, active_tools=[\"wheel_zoom\"], tools=[hover]),\n",
    "    )\n",
    "    #* graph.select(circle='Cluster').opts(\n",
    "    #    edge_alpha=0, edge_hover_alpha=1,\n",
    "    #    edge_hover_line_color=\"white\",\n",
    "    #    node_color='Cluster'\n",
    "    #)\n",
    "    * labels.opts(text_font_size='8pt', text_color='grey')\n",
    ")\n",
    "\n",
    "\n",
    "hv.save(graph, get_filename(\"output/cluster\", \"html\"))\n",
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23d21997ad725a206dd9184d6b9fd46a7084bb2c06bc687598ce57c6f0eaa752"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
